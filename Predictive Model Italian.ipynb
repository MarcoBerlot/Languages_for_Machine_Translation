{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from googletrans import Translator  # Import Translator module from googletrans package\n",
    "import _dynet as dy\n",
    "import re\n",
    "\n",
    "train_italian = pickle.load(open(\"train_italian.pkl\", \"rb\"))\n",
    "test_italian = pickle.load(open(\"test_italian.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCorpus():\n",
    "    corpus_it_italian=[]\n",
    "    corpus_en_italian=[]\n",
    "    puncList = [\".\",\";\",\":\",\"!\",\"?\",\"/\",\"\\\\\",\",\",\"#\",\"@\",\"$\",\"&\",\")\",\"(\",\"\\\"\",\"...\"]\n",
    "    i=0\n",
    "    with open (\"train_it_italian.it\", \"r\",encoding=\"utf8\") as myfile:\n",
    "        for line in myfile:\n",
    "            sentence=[]\n",
    "            for word in line.split(\" \"):\n",
    "                word=word.replace(\"\\n\",\"\")\n",
    "                if(word not in puncList):\n",
    "                    if word.replace('.','',1).isdigit():\n",
    "                        word=\"DIG\"\n",
    "                    sentence.append(word) \n",
    "            corpus_it_italian.append(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    with open (\"train_en_italian.en\", \"r\",encoding=\"utf8\") as myfile:\n",
    "        for line in myfile:\n",
    "            sentence=[]\n",
    "            for word in line.split(\" \"):\n",
    "                word=word.replace(\"\\n\",\"\")\n",
    "                if(word not in puncList):\n",
    "                    if word.replace('.','',1).isdigit():\n",
    "                        word=\"DIG\"\n",
    "                    word=re.sub(r'[^\\w\\s]','',word)\n",
    "\n",
    "                    sentence.append(word) \n",
    "            corpus_en_italian.append(sentence)\n",
    "\n",
    "    with open('corpus_en_italian.pkl', 'wb') as f:\n",
    "        pickle.dump(corpus_en_italian, f)\n",
    "    with open('corpus_it_italian.pkl', 'wb') as f:\n",
    "        pickle.dump(corpus_it_italian, f)\n",
    "    \n",
    "    return corpus_en_italian, corpus_it_italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corpus_en_italian, corpus_it_italian = createCorpus()\n",
    "corpus_en_italian = pickle.load(open(\"corpus_en_italian.pkl\", \"rb\"))\n",
    "corpus_it_italian = pickle.load(open(\"corpus_it_italian.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dictionary for word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createW2V():\n",
    "    model_en_italian=word2vec.Word2Vec(corpus_en_italian,min_count=1)\n",
    "    model_it_italian=word2vec.Word2Vec(corpus_it_italian,min_count=1)\n",
    "\n",
    "    with open('model_en_italian.pkl', 'wb') as f:\n",
    "        pickle.dump(model_en_italian, f)\n",
    "    with open('model_it_italian.pkl', 'wb') as f:\n",
    "        pickle.dump(model_it_italian, f)\n",
    "    \n",
    "    return model_en_italian, model_it_italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_en_italian, model_it_italian = createW2V()\n",
    "model_en_italian = pickle.load(open(\"model_en_italian.pkl\", \"rb\"))\n",
    "model_it_italian = pickle.load(open(\"model_it_italian.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_it = model_it_italian[model_it_italian.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_en = model_en_italian[model_en_italian.wv.vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "result_it_pca = pca.fit_transform(X_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "result_en_pca = pca.fit_transform(X_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cane\n",
      "gatto\n",
      "uomo\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29c1da080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#FRENCH\n",
    "# create a scatter plot of the projection\n",
    "index_it=[list(model_it_italian.wv.vocab).index(\"cane\"),list(model_it_italian.wv.vocab).index(\"gatto\"),list(model_it_italian.wv.vocab).index(\"uomo\")]\n",
    "result_it=np.array([result_it_pca[i] for i in index_it])\n",
    "plt.scatter(-result_it[:, 0],-result_it[:, 1])\n",
    "it_words = [ list(model_it_italian.wv.vocab)[i] for i in index_it]\n",
    "for i, word in enumerate(it_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(-result_it[i, 0], -result_it[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "dog\n",
      "human\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEiSCkNBklT8P7ffiskmuPXFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bdfed8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ENGLISH\n",
    "# create a scatter plot of the projection\n",
    "index_en=[list(model_en_italian.wv.vocab).index(\"cat\"),list(model_en_italian.wv.vocab).index(\"dog\"),list(model_en_italian.wv.vocab).index(\"human\")]\n",
    "result_en=np.array([result_en_pca[i] for i in index_en])\n",
    "plt.scatter(result_en[:, 0], result_en[:, 1])\n",
    "en_words = [ list(model_en_italian.wv.vocab)[i] for i in index_en]\n",
    "for i, word in enumerate(en_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(result_en[i, 0], result_en[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_word = []\n",
    "english_vocab = set()\n",
    "for sentence in corpus_en_italian:\n",
    "    for word in sentence:\n",
    "        all_word.append(word)\n",
    "        english_vocab.add(word)\n",
    "        \n",
    "italian_vocab = set()\n",
    "for sentence in corpus_it_italian:\n",
    "    for word in sentence:\n",
    "        italian_vocab.add(word)\n",
    "        \n",
    "counts = Counter(all_word)\n",
    "common_vocab = set()\n",
    "train_vocab = set()\n",
    "for word in counts.most_common(20000):\n",
    "    common_vocab.add(word[0])\n",
    "for word in counts.most_common(10000):\n",
    "    train_vocab.add(word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pairs of English-Italian Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateWordPairs():\n",
    "#     word_pairs_it = []\n",
    "#     word_pairs_smaller_it = []\n",
    "    \n",
    "    word_pairs_it = pickle.load(open(\"word_pairs_it.pkl\", \"rb\"))\n",
    "    word_pairs_smaller_it = pickle.load(open(\"word_pairs_smaller_it.pkl\", \"rb\"))\n",
    "\n",
    "    count = 0\n",
    "    for word in english_vocab:\n",
    "        if count == 1000:\n",
    "            break\n",
    "        print(count)\n",
    "        count += 1\n",
    "        translator = Translator()\n",
    "        italian_word = translator.translate(word,src=\"en\",dest=\"it\").text\n",
    "        if italian_word in italian_vocab:\n",
    "            word_pairs_it.append((word, italian_word))\n",
    "            if italian_word != word:\n",
    "                word_pairs_smaller_it.append((word, italian_word))\n",
    "\n",
    "    with open('word_pairs_it.pkl', 'wb') as f:\n",
    "        pickle.dump(word_pairs_it, f)\n",
    "    with open('word_pairs_smaller_it.pkl', 'wb') as f:\n",
    "        pickle.dump(word_pairs_smaller_it, f)\n",
    "    \n",
    "    return word_pairs_it, word_pairs_smaller_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_pairs_it, word_pairs_smaller_it = generateWordPairs()\n",
    "word_pairs_it = pickle.load(open(\"word_pairs_it.pkl\", \"rb\"))\n",
    "word_pairs_smaller_it = pickle.load(open(\"word_pairs_smaller_it.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Method  -----This is the method for generating transformation matrix, make sure to run all code above this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIMM = X_en.shape[1]\n",
    "HIDDEN = 1000\n",
    "en_list = list(model_en_italian.wv.vocab)\n",
    "training_tuples = pickle.load(open(\"training_tuples.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_pair_italian = set()\n",
    "# SIZE = 15000\n",
    "# words = np.random.choice(list(common_vocab),size=SIZE,replace=False)\n",
    "# for i, word_en in enumerate(words):\n",
    "#     if i % 100 == 0:\n",
    "#         print(i)\n",
    "#     translator = Translator()\n",
    "#     word_it = translator.translate(word_en,src=\"en\",dest=\"it\").text\n",
    "#     if word_it not in italian_vocab:\n",
    "#         continue\n",
    "#     word_pair_italian.add((word_en,word_it))\n",
    "# with open('word_pair_italian.pkl', 'wb') as f:\n",
    "#     pickle.dump(word_pair_italian, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_italian = set()\n",
    "# count = 0\n",
    "# for tup in word_pair_italian:\n",
    "#     if count == 10000:\n",
    "#         break\n",
    "#     train_italian.add(tup)\n",
    "#     count += 1\n",
    "# test_italian = word_pair_italian - train_italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('train_italian.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_italian, f)\n",
    "# with open('test_italian.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_italian, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTransormMatImproved():\n",
    "    \n",
    "#     training_tuples = pickle.load(open(\"training_tuples.pkl\", \"rb\"))\n",
    "\n",
    "    dyparams = dy.DynetParams()\n",
    "    dyparams.set_mem(2048)\n",
    "    dyparams.set_autobatch(True)\n",
    "    dyparams.init()\n",
    "\n",
    "    # create a parameter collection and add the parameters.\n",
    "    m = dy.ParameterCollection()\n",
    "#     pW = m.add_parameters((HIDDEN,DIMM))\n",
    "    pW = m.add_parameters((DIMM,DIMM))\n",
    "    pb = m.add_parameters((HIDDEN))\n",
    "    pC = m.add_parameters((DIMM,HIDDEN))\n",
    "\n",
    "    dy.renew_cg() # new computation graph. not strictly needed here, but good practice.\n",
    "\n",
    "    # associate the parameters with cg Expressions\n",
    "    W = dy.parameter(pW)\n",
    "    b = dy.parameter(pb)\n",
    "    C = dy.parameter(pC)\n",
    "\n",
    "    x = dy.vecInput(DIMM) # an input vector of size 2. Also an expression.\n",
    "    y = dy.vecInput(DIMM)\n",
    "#     output = C*(W*x + b)\n",
    "    output = W*x\n",
    "    \n",
    "    SIZE = 10000\n",
    "\n",
    "    trainer = dy.AdagradTrainer(m)\n",
    "\n",
    "    en_list = list(model_en_italian.wv.vocab)\n",
    "    it_list = list(model_it_italian.wv.vocab)\n",
    "\n",
    "\n",
    "    EPOCHS = 3\n",
    "\n",
    "    words = np.random.choice(list(common_vocab),size=SIZE,replace=False)\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        seen_instances = 0\n",
    "        for i,tup in enumerate(train_italian):\n",
    "            word_en = tup[0]\n",
    "            word_it = tup[1]\n",
    "#             translator = Translator()\n",
    "#             word_it = translator.translate(word_en,src=\"en\",dest=\"it\").text\n",
    "            if word_it not in italian_vocab:\n",
    "                continue\n",
    "                \n",
    "#             training_tuples.add((word_en,word_it))\n",
    "            \n",
    "            en_emb = X_en[en_list.index(word_en)]\n",
    "            it_emb = X_it[it_list.index(word_it)]\n",
    "\n",
    "            en_emb /= np.linalg.norm(en_emb)\n",
    "            it_emb /= np.linalg.norm(it_emb)\n",
    "\n",
    "            x.set(en_emb)\n",
    "            y.set(it_emb)\n",
    "        \n",
    "#             loss = 1 - dy.dot_product(output,y) / (dy.l2_norm(output) * dy.l2_norm(y)).value()\n",
    "            \n",
    "            loss = dy.squared_distance(output,y)\n",
    "        \n",
    "            seen_instances += 1\n",
    "            total_loss += loss.value()\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            \n",
    "#             tmp = W.value()\n",
    "#             u, s, vh = np.linalg.svd(tmp, full_matrices=True)\n",
    "#             newW = np.dot(u,vh)\n",
    "            \n",
    "#             pW = m.add_parameters((DIMM,DIMM),init=dy.NumpyInitializer(newW))\n",
    "#             W = dy.parameter(pW)\n",
    "\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(total_loss / seen_instances)\n",
    "                print(i)\n",
    "\n",
    "    mat = W.value()\n",
    "    matC = C.value()\n",
    "    matB = b.value()\n",
    "    \n",
    "#     with open('training_tuples.pkl', 'wb') as f:\n",
    "#         pickle.dump(training_tuples, f)\n",
    "    \n",
    "    return mat, matC, matB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.795987844467163\n",
      "0\n",
      "2.755272360131292\n",
      "100\n",
      "2.1560421120468063\n",
      "200\n",
      "1.8330941628974142\n",
      "300\n",
      "1.6452576390228366\n",
      "400\n",
      "1.51933544451843\n",
      "500\n",
      "1.4219418831058033\n",
      "600\n",
      "1.3456849386110454\n",
      "700\n",
      "1.2780684685885684\n",
      "800\n",
      "1.230099617806444\n",
      "900\n",
      "1.1856827623211779\n",
      "1000\n",
      "1.147366410556108\n",
      "1100\n",
      "1.1158415323292386\n",
      "1200\n",
      "1.0869323761072827\n",
      "1300\n",
      "1.062023951146196\n",
      "1400\n",
      "1.0434557540388127\n",
      "1500\n",
      "1.0248894043857795\n",
      "1600\n",
      "1.007594267325777\n",
      "1700\n",
      "0.9933064305355389\n",
      "1800\n",
      "0.98175070110683\n",
      "1900\n",
      "0.970069638293782\n",
      "2000\n",
      "0.9603794145121681\n",
      "2100\n",
      "0.9495064856476916\n",
      "2200\n",
      "0.9410186630909674\n",
      "2300\n",
      "0.9313286229477779\n",
      "2400\n",
      "0.923685619529368\n",
      "2500\n",
      "0.9172047127535232\n",
      "2600\n",
      "0.9115926381538463\n",
      "2700\n",
      "0.9054969263870518\n",
      "2800\n",
      "0.8980496438494308\n",
      "2900\n",
      "0.8918042267185178\n",
      "3000\n",
      "0.886258340072186\n",
      "3100\n",
      "0.8812183580410476\n",
      "3200\n",
      "0.8748251038793361\n",
      "3300\n",
      "0.869737626510976\n",
      "3400\n",
      "0.8656380137344049\n",
      "3500\n",
      "0.8621373459080198\n",
      "3600\n",
      "0.8584357771606775\n",
      "3700\n",
      "0.8547004820194347\n",
      "3800\n",
      "0.8509720520304277\n",
      "3900\n",
      "0.8475028202589439\n",
      "4000\n",
      "0.8445750359637479\n",
      "4100\n",
      "0.8407844996961688\n",
      "4200\n",
      "0.8371729612163377\n",
      "4300\n",
      "0.8349651748606953\n",
      "4400\n",
      "0.831938449530913\n",
      "4500\n",
      "0.8291458539880118\n",
      "4600\n",
      "0.8265569847686522\n",
      "4700\n",
      "0.8230127285133176\n",
      "4800\n",
      "0.8189472804852005\n",
      "4900\n",
      "0.816069667767439\n",
      "5000\n",
      "0.8140352567377755\n",
      "5100\n",
      "0.8117408244352207\n",
      "5200\n",
      "0.8089812711215744\n",
      "5300\n",
      "0.8065196870240078\n",
      "5400\n",
      "0.80452649315917\n",
      "5500\n",
      "0.8036108046791379\n",
      "5600\n",
      "0.8012473446938934\n",
      "5700\n",
      "0.799069117560117\n",
      "5800\n",
      "0.7972780049599706\n",
      "5900\n",
      "0.795710947002655\n",
      "6000\n",
      "0.7942475823081335\n",
      "6100\n",
      "0.7923268933408473\n",
      "6200\n",
      "0.7903974970698905\n",
      "6300\n",
      "0.7885643253334238\n",
      "6400\n",
      "0.7874389441540344\n",
      "6500\n",
      "0.7858870733196925\n",
      "6600\n",
      "0.7847913526795797\n",
      "6700\n",
      "0.7828959600769619\n",
      "6800\n",
      "0.7817835594982085\n",
      "6900\n",
      "0.7805302586981678\n",
      "7000\n",
      "0.7795746008404005\n",
      "7100\n",
      "0.7784801384977559\n",
      "7200\n",
      "0.7772594894930657\n",
      "7300\n",
      "0.77550089386867\n",
      "7400\n",
      "0.7743190087933267\n",
      "7500\n",
      "0.7727023147447473\n",
      "7600\n",
      "0.7713476945430238\n",
      "7700\n",
      "0.7705694762575612\n",
      "7800\n",
      "0.7698040685066315\n",
      "7900\n",
      "0.7685221092166222\n",
      "8000\n",
      "0.767132792934093\n",
      "8100\n",
      "0.7665659415094668\n",
      "8200\n",
      "0.7657693323636972\n",
      "8300\n",
      "0.7641480356036248\n",
      "8400\n",
      "0.7635691230482332\n",
      "8500\n",
      "0.7626892655460713\n",
      "8600\n",
      "0.7617123536101951\n",
      "8700\n",
      "0.7606792070268704\n",
      "8800\n",
      "0.7599983053128514\n",
      "8900\n",
      "0.7591617864484906\n",
      "9000\n",
      "0.7583842775596654\n",
      "9100\n",
      "0.7574522246609381\n",
      "9200\n",
      "0.7567513172645208\n",
      "9300\n",
      "0.7561932766219426\n",
      "9400\n",
      "0.7558868730203715\n",
      "9500\n",
      "0.7549004018285004\n",
      "9600\n",
      "0.7539139427210102\n",
      "9700\n",
      "0.7529131812293874\n",
      "9800\n",
      "0.7519939692002235\n",
      "9900\n",
      "0.5812796354293823\n",
      "0\n",
      "0.6327185686862115\n",
      "100\n",
      "0.6646216866092303\n",
      "200\n",
      "0.661083100196531\n",
      "300\n",
      "0.670663694639753\n",
      "400\n",
      "0.6767507883127102\n",
      "500\n",
      "0.6789849406470871\n",
      "600\n",
      "0.6800880642573266\n",
      "700\n",
      "0.6759660625911682\n",
      "800\n",
      "0.6771858877995435\n",
      "900\n",
      "0.6746699745868231\n",
      "1000\n",
      "0.6720398196326289\n",
      "1100\n",
      "0.6709275047894223\n",
      "1200\n",
      "0.6695950104812766\n",
      "1300\n",
      "0.6676776212168795\n",
      "1400\n",
      "0.6696392163127999\n",
      "1500\n",
      "0.6692621833287054\n",
      "1600\n",
      "0.668887312739194\n",
      "1700\n",
      "0.6697270094041093\n",
      "1800\n",
      "0.6715393649048708\n",
      "1900\n",
      "0.6723489638107053\n",
      "2000\n",
      "0.6740675137361875\n",
      "2100\n",
      "0.6736123057954803\n",
      "2200\n",
      "0.6748653701055263\n",
      "2300\n",
      "0.6742114785659914\n",
      "2400\n",
      "0.6752017665355027\n",
      "2500\n",
      "0.6764428313192795\n",
      "2600\n",
      "0.6777697099674106\n",
      "2700\n",
      "0.6785094789024848\n",
      "2800\n",
      "0.6775147596265644\n",
      "2900\n",
      "0.6774176974141252\n",
      "3000\n",
      "0.6775487606149072\n",
      "3100\n",
      "0.6777832758488115\n",
      "3200\n",
      "0.6764388765278674\n",
      "3300\n",
      "0.6762379115336223\n",
      "3400\n",
      "0.676662670590475\n",
      "3500\n",
      "0.6774762628542585\n",
      "3600\n",
      "0.6778249667202\n",
      "3700\n",
      "0.6779564888469172\n",
      "3800\n",
      "0.67785934137858\n",
      "3900\n",
      "0.6780135355958697\n",
      "4000\n",
      "0.6784658520229268\n",
      "4100\n",
      "0.6779190024090108\n",
      "4200\n",
      "0.6774181325375771\n",
      "4300\n",
      "0.6782054700747968\n",
      "4400\n",
      "0.6780477338328782\n",
      "4500\n",
      "0.6779905770025002\n",
      "4600\n",
      "0.6780616273824978\n",
      "4700\n",
      "0.6770457772879868\n",
      "4800\n",
      "0.6754975157279284\n",
      "4900\n",
      "0.6750263925302842\n",
      "5000\n",
      "0.6752820544542226\n",
      "5100\n",
      "0.6751885857462447\n",
      "5200\n",
      "0.6745564840049524\n",
      "5300\n",
      "0.6741665335655919\n",
      "5400\n",
      "0.6741744935014122\n",
      "5500\n",
      "0.6751935689646397\n",
      "5600\n",
      "0.6746744577052656\n",
      "5700\n",
      "0.674287592187213\n",
      "5800\n",
      "0.6742726491555544\n",
      "5900\n",
      "0.674382021324453\n",
      "6000\n",
      "0.6745773874634778\n",
      "6100\n",
      "0.6742857057727973\n",
      "6200\n",
      "0.6739197671058689\n",
      "6300\n",
      "0.6736498766160722\n",
      "6400\n",
      "0.6739422705880019\n",
      "6500\n",
      "0.6738361437119168\n",
      "6600\n",
      "0.6741511800332384\n",
      "6700\n",
      "0.6735986753489722\n",
      "6800\n",
      "0.6738335854820438\n",
      "6900\n",
      "0.6738746282356566\n",
      "7000\n",
      "0.6741728083048383\n",
      "7100\n",
      "0.6742893824861573\n",
      "7200\n",
      "0.6742591446367883\n",
      "7300\n",
      "0.6736807713813354\n",
      "7400\n",
      "0.6736490382657593\n",
      "7500\n",
      "0.6731287722441887\n",
      "7600\n",
      "0.672876152345506\n",
      "7700\n",
      "0.6731616076487422\n",
      "7800\n",
      "0.6734346758865161\n",
      "7900\n",
      "0.6731622633099958\n",
      "8000\n",
      "0.6727662289246352\n",
      "8100\n",
      "0.6731781948886111\n",
      "8200\n",
      "0.6733197560225348\n",
      "8300\n",
      "0.6726257289510272\n",
      "8400\n",
      "0.6729654960019661\n",
      "8500\n",
      "0.6729700473758623\n",
      "8600\n",
      "0.6728582438460411\n",
      "8700\n",
      "0.6726653884062238\n",
      "8800\n",
      "0.6728101995031883\n",
      "8900\n",
      "0.6727843356389441\n",
      "9000\n",
      "0.6727924780876554\n",
      "9100\n",
      "0.6726364938396693\n",
      "9200\n",
      "0.6726985251713845\n",
      "9300\n",
      "0.6728946044494238\n",
      "9400\n",
      "0.6733253647742579\n",
      "9500\n",
      "0.6730557357832835\n",
      "9600\n",
      "0.6727839321137679\n",
      "9700\n",
      "0.6725098645154365\n",
      "9800\n",
      "0.672268918076256\n",
      "9900\n",
      "0.5620806217193604\n",
      "0\n",
      "0.6234258817564143\n",
      "100\n",
      "0.6542089249364179\n",
      "200\n",
      "0.6502667015969159\n",
      "300\n",
      "0.6593998452820385\n",
      "400\n",
      "0.6654643130576063\n",
      "500\n",
      "0.667543718675012\n",
      "600\n",
      "0.6688121222650444\n",
      "700\n",
      "0.6647636369521847\n",
      "800\n",
      "0.6657647662501489\n",
      "900\n",
      "0.6633612877065009\n",
      "1000\n",
      "0.6607576688238971\n",
      "1100\n",
      "0.6595427920602939\n",
      "1200\n",
      "0.6583045364731921\n",
      "1300\n",
      "0.6565428244310307\n",
      "1400\n",
      "0.6586010663073354\n",
      "1500\n",
      "0.658208098553405\n",
      "1600\n",
      "0.6578797147965726\n",
      "1700\n",
      "0.6587960560046455\n",
      "1800\n",
      "0.660631713170807\n",
      "1900\n",
      "0.6614205587109824\n",
      "2000\n",
      "0.6631458517215412\n",
      "2100\n",
      "0.6627497660848348\n",
      "2200\n",
      "0.6640557946911692\n",
      "2300\n",
      "0.6634767990169899\n",
      "2400\n",
      "0.6645464056947145\n",
      "2500\n",
      "0.6658379619555124\n",
      "2600\n",
      "0.6671507098925462\n",
      "2700\n",
      "0.6679439765242584\n",
      "2800\n",
      "0.66703022250078\n",
      "2900\n",
      "0.6669936669554086\n",
      "3000\n",
      "0.6671898632338261\n",
      "3100\n",
      "0.6674457908756694\n",
      "3200\n",
      "0.6661515670657266\n",
      "3300\n",
      "0.6660303293966399\n",
      "3400\n",
      "0.666505582279493\n",
      "3500\n",
      "0.6673655206670168\n",
      "3600\n",
      "0.6677404347786031\n",
      "3700\n",
      "0.6678906674253035\n",
      "3800\n",
      "0.6678118264138836\n",
      "3900\n",
      "0.6680282310370176\n",
      "4000\n",
      "0.6685237280226893\n",
      "4100\n",
      "0.6680038711076065\n",
      "4200\n",
      "0.6675440384790915\n",
      "4300\n",
      "0.6683626611431576\n",
      "4400\n",
      "0.6682434205749622\n",
      "4500\n",
      "0.668213240081682\n",
      "4600\n",
      "0.6683213987380386\n",
      "4700\n",
      "0.6673423331048532\n",
      "4800\n",
      "0.6658518898094267\n",
      "4900\n",
      "0.6654275661467361\n",
      "5000\n",
      "0.6657273158696885\n",
      "5100\n",
      "0.6656711930392958\n",
      "5200\n",
      "0.6650668447578972\n",
      "5300\n",
      "0.6647136135937616\n",
      "5400\n",
      "0.6647581035300745\n",
      "5500\n",
      "0.6658130835910031\n",
      "5600\n",
      "0.6653169404255928\n",
      "5700\n",
      "0.6649570778009707\n",
      "5800\n",
      "0.6649846064980768\n",
      "5900\n",
      "0.6651181493713705\n",
      "6000\n",
      "0.6653563957969745\n",
      "6100\n",
      "0.665110489787584\n",
      "6200\n",
      "0.6647773758652966\n",
      "6300\n",
      "0.6645638551391339\n",
      "6400\n",
      "0.6648722714877022\n",
      "6500\n",
      "0.6648009354134361\n",
      "6600\n",
      "0.6651553712666275\n",
      "6700\n",
      "0.6646312169556476\n",
      "6800\n",
      "0.6649087738613342\n",
      "6900\n",
      "0.6649847448578802\n",
      "7000\n",
      "0.6653155915868264\n",
      "7100\n",
      "0.6654600131376769\n",
      "7200\n",
      "0.6654587005335343\n",
      "7300\n",
      "0.6649169619442433\n",
      "7400\n",
      "0.6649220892011031\n",
      "7500\n",
      "0.6644281315840384\n",
      "7600\n",
      "0.664216594243031\n",
      "7700\n",
      "0.6645350076593416\n",
      "7800\n",
      "0.664840717049222\n",
      "7900\n",
      "0.664600809765315\n",
      "8000\n",
      "0.6642357751813557\n",
      "8100\n",
      "0.6646805497138707\n",
      "8200\n",
      "0.6648487362670922\n",
      "8300\n",
      "0.664186145321427\n",
      "8400\n",
      "0.6645622403919521\n",
      "8500\n",
      "0.6645971843911083\n",
      "8600\n",
      "0.6645110261798549\n",
      "8700\n",
      "0.6643396828265613\n",
      "8800\n",
      "0.6645088054305877\n",
      "8900\n",
      "0.6645110814392718\n",
      "9000\n",
      "0.6645377680958922\n",
      "9100\n",
      "0.6644030628632157\n",
      "9200\n",
      "0.6644876690103013\n",
      "9300\n",
      "0.6647087419071726\n",
      "9400\n",
      "0.6651640658443971\n",
      "9500\n",
      "0.6649163612961434\n",
      "9600\n",
      "0.6646714096827651\n",
      "9700\n",
      "0.6644348909983573\n",
      "9800\n",
      "0.6642156808698506\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "# mat_italian, C, b = generateTransormMatImproved()\n",
    "mat_italian = pickle.load(open(\"mat_italian.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Prediction Method -- this is the prediction method using transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_arr = np.array(list(model_it_italian.wv.vocab))\n",
    "X_it_mag = np.sum(X_it**2,axis=1)**0.5\n",
    "def predict_cosineSim(word_en,topWords):\n",
    "    en_emb = X_en[en_list.index(word_en)]\n",
    "#     out = (np.dot(C,(np.dot(mat,en_emb.reshape((DIMM,1))) + np.array(b).reshape((HIDDEN,1))))).flatten()\n",
    "    out = np.dot(mat_italian,en_emb.reshape((DIMM,1))).flatten()\n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "    \n",
    "    out_mag = np.sum(out**2)**0.5\n",
    "    cos_sim = np.sum((X_it * out),axis=1)/(X_it_mag*out_mag)\n",
    "    return list(word_arr[np.argsort(cos_sim)[::-1][:topWords]])#, french_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cellulare',\n",
       " 'musicali',\n",
       " 'computer',\n",
       " 'radar',\n",
       " 'plastica',\n",
       " 'video',\n",
       " 'computer.',\n",
       " 'software',\n",
       " 'satellitari',\n",
       " 'hardware']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cosineSim('computer',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worse Prediction Method -- ignore this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_arr = np.array(list(model_it_italian.wv.vocab))\n",
    "def predict_closest(word_en,topWords):\n",
    "    en_emb = X_en[en_list.index(word_en)]\n",
    "    out = np.dot(mat,en_emb.reshape((DIMM,1))).flatten()\n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "    \n",
    "    return list(word_arr[np.argsort(np.sum((X_it - out) ** 2,axis=1))[:topWords]])#, french_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solidale?', 'fragile:', 'discernibili.', 'congeniale.', 'buia.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_closest('fast',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of Model -- running this gets the accuracy -- not implemented correctly yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "INCORRECT:  heavens\n",
      "1\n",
      "INCORRECT:  Rarely\n",
      "2\n",
      "INCORRECT:  burgeoning\n",
      "3\n",
      "CORRECT:  Rainsy\n",
      "4\n",
      "CORRECT:  unjustifiable\n",
      "5\n",
      "INCORRECT:  Győri\n",
      "6\n",
      "INCORRECT:  quotes\n",
      "7\n",
      "INCORRECT:  Tindemans\n",
      "8\n",
      "INCORRECT:  fans\n",
      "9\n",
      "INCORRECT:  accompanied\n",
      "10\n",
      "CORRECT:  Wim\n",
      "11\n",
      "INCORRECT:  illnesses\n",
      "12\n",
      "CORRECT:  Havel\n",
      "13\n",
      "INCORRECT:  edge\n",
      "14\n",
      "INCORRECT:  footnote\n",
      "15\n",
      "INCORRECT:  rosé\n",
      "16\n",
      "CORRECT:  Indeed\n",
      "17\n",
      "INCORRECT:  attached\n",
      "18\n",
      "INCORRECT:  Are\n",
      "19\n",
      "INCORRECT:  Karin\n",
      "20\n",
      "INCORRECT:  nitrate\n",
      "21\n",
      "INCORRECT:  moon\n",
      "22\n",
      "INCORRECT:  Goerens\n",
      "23\n",
      "INCORRECT:  outcry\n",
      "24\n",
      "INCORRECT:  offered\n",
      "25\n",
      "INCORRECT:  anyway\n",
      "26\n",
      "CORRECT:  greed\n",
      "27\n",
      "INCORRECT:  discharge\n",
      "28\n",
      "INCORRECT:  Kirkhope\n",
      "29\n",
      "CORRECT:  fathers\n",
      "30\n",
      "INCORRECT:  Campaign\n",
      "31\n",
      "CORRECT:  interconnections\n",
      "32\n",
      "INCORRECT:  MDGs\n",
      "33\n",
      "CORRECT:  passionate\n",
      "34\n",
      "CORRECT:  threaten\n",
      "35\n",
      "CORRECT:  eloquent\n",
      "36\n",
      "CORRECT:  irritated\n",
      "37\n",
      "CORRECT:  insufficient\n",
      "38\n",
      "CORRECT:  foresight\n",
      "39\n",
      "INCORRECT:  captive\n",
      "40\n",
      "INCORRECT:  standpoints\n",
      "41\n",
      "INCORRECT:  While\n",
      "42\n",
      "INCORRECT:  monitored\n",
      "43\n",
      "CORRECT:  instigated\n",
      "44\n",
      "CORRECT:  Ombudsman\n",
      "45\n",
      "CORRECT:  Herbert\n",
      "46\n",
      "CORRECT:  copper\n",
      "47\n",
      "INCORRECT:  tightly\n",
      "48\n",
      "INCORRECT:  Vedova\n",
      "49\n",
      "INCORRECT:  Hardly\n",
      "50\n",
      "INCORRECT:  Bureaus\n",
      "51\n",
      "INCORRECT:  stalling\n",
      "52\n",
      "CORRECT:  closed\n",
      "53\n",
      "CORRECT:  market\n",
      "54\n",
      "INCORRECT:  overcoming\n",
      "55\n",
      "CORRECT:  imperative\n",
      "56\n",
      "INCORRECT:  births\n",
      "57\n",
      "INCORRECT:  Almadén\n",
      "58\n",
      "INCORRECT:  Stenmarck\n",
      "59\n",
      "INCORRECT:  grounded\n",
      "60\n",
      "INCORRECT:  demographics\n",
      "61\n",
      "INCORRECT:  Improved\n",
      "62\n",
      "INCORRECT:  Lax\n",
      "63\n",
      "INCORRECT:  twelfth\n",
      "64\n",
      "INCORRECT:  decreased\n",
      "65\n",
      "CORRECT:  entrepreneur\n",
      "66\n",
      "INCORRECT:  relaxed\n",
      "67\n",
      "INCORRECT:  East\n",
      "68\n",
      "INCORRECT:  adherents\n",
      "69\n",
      "INCORRECT:  labour\n",
      "70\n",
      "CORRECT:  insulted\n",
      "71\n",
      "INCORRECT:  realm\n",
      "72\n",
      "INCORRECT:  January\n",
      "73\n",
      "CORRECT:  Stauner\n",
      "74\n",
      "INCORRECT:  Viola\n",
      "75\n",
      "INCORRECT:  additives\n",
      "76\n",
      "CORRECT:  PNR\n",
      "77\n",
      "INCORRECT:  Kigali\n",
      "78\n",
      "INCORRECT:  amounting\n",
      "79\n",
      "INCORRECT:  adjust\n",
      "80\n",
      "CORRECT:  supremacy\n",
      "81\n",
      "INCORRECT:  fruition\n",
      "82\n",
      "INCORRECT:  Hemicycle\n",
      "83\n",
      "INCORRECT:  adjournment\n",
      "84\n",
      "INCORRECT:  Proper\n",
      "85\n",
      "CORRECT:  patrols\n",
      "86\n",
      "INCORRECT:  inventors\n",
      "87\n",
      "INCORRECT:  EFSA\n",
      "88\n",
      "INCORRECT:  IACS\n",
      "89\n",
      "CORRECT:  Eurojust\n",
      "90\n",
      "CORRECT:  hierarchy\n",
      "91\n",
      "INCORRECT:  timescale\n",
      "92\n",
      "INCORRECT:  wire\n",
      "93\n",
      "CORRECT:  spiritual\n",
      "94\n",
      "INCORRECT:  Interinstitutional\n",
      "95\n",
      "INCORRECT:  Nations\n",
      "96\n",
      "INCORRECT:  Powell\n",
      "97\n",
      "CORRECT:  Calais\n",
      "98\n",
      "CORRECT:  impressions\n",
      "99\n",
      "INCORRECT:  Association\n",
      "100\n",
      "CORRECT:  regulation\n",
      "101\n",
      "CORRECT:  commercial\n",
      "102\n",
      "INCORRECT:  circuit\n",
      "103\n",
      "INCORRECT:  beekeepers\n",
      "104\n",
      "INCORRECT:  landfills\n",
      "105\n",
      "INCORRECT:  gentleman\n",
      "106\n",
      "INCORRECT:  stuck\n",
      "107\n",
      "INCORRECT:  wool\n",
      "108\n",
      "CORRECT:  Lagendijk\n",
      "109\n",
      "INCORRECT:  whom\n",
      "110\n",
      "INCORRECT:  gladly\n",
      "111\n",
      "CORRECT:  ethnic\n",
      "112\n",
      "INCORRECT:  precept\n",
      "113\n",
      "CORRECT:  inaccessible\n",
      "114\n",
      "INCORRECT:  realities\n",
      "115\n",
      "INCORRECT:  Reports\n",
      "116\n",
      "CORRECT:  trapped\n",
      "117\n",
      "CORRECT:  cradle\n",
      "118\n",
      "INCORRECT:  Internal\n",
      "119\n",
      "INCORRECT:  repetition\n",
      "120\n",
      "INCORRECT:  invitations\n",
      "121\n",
      "CORRECT:  g\n",
      "122\n",
      "INCORRECT:  elite\n",
      "123\n",
      "INCORRECT:  consciously\n",
      "124\n",
      "INCORRECT:  responded\n",
      "125\n",
      "CORRECT:  enhances\n",
      "126\n",
      "INCORRECT:  sketched\n",
      "127\n",
      "INCORRECT:  dietary\n",
      "128\n",
      "INCORRECT:  Financial\n",
      "129\n",
      "INCORRECT:  annexes\n",
      "130\n",
      "INCORRECT:  selfish\n",
      "131\n",
      "CORRECT:  contradict\n",
      "132\n",
      "INCORRECT:  dawn\n",
      "133\n",
      "CORRECT:  laundering\n",
      "134\n",
      "CORRECT:  observations\n",
      "135\n",
      "CORRECT:  selective\n",
      "136\n",
      "CORRECT:  childrens\n",
      "137\n",
      "CORRECT:  defend\n",
      "138\n",
      "CORRECT:  proposes\n",
      "139\n",
      "INCORRECT:  nurseries\n",
      "140\n",
      "INCORRECT:  bird\n",
      "141\n",
      "CORRECT:  April\n",
      "142\n",
      "INCORRECT:  cleanup\n",
      "143\n",
      "INCORRECT:  appropriate\n",
      "144\n",
      "INCORRECT:  servicing\n",
      "145\n",
      "INCORRECT:  release\n",
      "146\n",
      "CORRECT:  influx\n",
      "147\n",
      "CORRECT:  duplicate\n",
      "148\n",
      "CORRECT:  ambiguous\n",
      "149\n",
      "INCORRECT:  disrupt\n",
      "150\n",
      "CORRECT:  Stalin\n",
      "151\n",
      "CORRECT:  amicable\n",
      "152\n",
      "INCORRECT:  countrys\n",
      "153\n",
      "CORRECT:  technology\n",
      "154\n",
      "INCORRECT:  diligently\n",
      "155\n",
      "CORRECT:  reduced\n",
      "156\n",
      "CORRECT:  Review\n",
      "157\n",
      "INCORRECT:  Integrated\n",
      "158\n",
      "CORRECT:  liberalized\n",
      "159\n",
      "CORRECT:  cultures\n",
      "160\n",
      "CORRECT:  acceded\n",
      "161\n",
      "INCORRECT:  topup\n",
      "162\n",
      "INCORRECT:  raises\n",
      "163\n",
      "INCORRECT:  Marinescu\n",
      "164\n",
      "INCORRECT:  Microsoft\n",
      "165\n",
      "INCORRECT:  steer\n",
      "166\n",
      "INCORRECT:  entering\n",
      "167\n",
      "CORRECT:  disproportionate\n",
      "168\n",
      "INCORRECT:  trick\n",
      "169\n",
      "CORRECT:  everywhere\n",
      "170\n",
      "INCORRECT:  disturbance\n",
      "171\n",
      "CORRECT:  victory\n",
      "172\n",
      "CORRECT:  Murcia\n",
      "173\n",
      "CORRECT:  Catherine\n",
      "174\n",
      "INCORRECT:  surprises\n",
      "175\n",
      "INCORRECT:  Junilistan\n",
      "176\n",
      "CORRECT:  journalists\n",
      "177\n",
      "INCORRECT:  Troika\n",
      "178\n",
      "INCORRECT:  disservice\n",
      "179\n",
      "INCORRECT:  flats\n",
      "180\n",
      "INCORRECT:  Vecchi\n",
      "181\n",
      "CORRECT:  beliefs\n",
      "182\n",
      "CORRECT:  saturation\n",
      "183\n",
      "INCORRECT:  healed\n",
      "184\n",
      "INCORRECT:  audacity\n",
      "185\n",
      "CORRECT:  option\n",
      "186\n",
      "CORRECT:  religions\n",
      "187\n",
      "INCORRECT:  immunities\n",
      "188\n",
      "CORRECT:  incentives\n",
      "189\n",
      "CORRECT:  harmless\n",
      "190\n",
      "CORRECT:  Try\n",
      "191\n",
      "CORRECT:  rivalry\n",
      "192\n",
      "CORRECT:  classify\n",
      "193\n",
      "CORRECT:  frequencies\n",
      "194\n",
      "INCORRECT:  autonomously\n",
      "195\n",
      "INCORRECT:  earth\n",
      "196\n",
      "INCORRECT:  custodian\n",
      "197\n",
      "CORRECT:  Protocol\n",
      "198\n",
      "CORRECT:  impossibility\n",
      "199\n",
      "INCORRECT:  deaf\n",
      "200\n",
      "CORRECT:  failings\n",
      "201\n",
      "INCORRECT:  Organic\n",
      "202\n",
      "INCORRECT:  footing\n",
      "203\n",
      "INCORRECT:  dichloromethane\n",
      "204\n",
      "INCORRECT:  Water\n",
      "205\n",
      "CORRECT:  admit\n",
      "206\n",
      "INCORRECT:  fog\n",
      "207\n",
      "INCORRECT:  nominee\n",
      "208\n",
      "INCORRECT:  flu\n",
      "209\n",
      "INCORRECT:  anchovy\n",
      "210\n",
      "CORRECT:  parking\n",
      "211\n",
      "CORRECT:  atmosphere\n",
      "212\n",
      "INCORRECT:  Corridor\n",
      "213\n",
      "CORRECT:  exacerbate\n",
      "214\n",
      "INCORRECT:  yards\n",
      "215\n",
      "CORRECT:  benzene\n",
      "216\n",
      "INCORRECT:  FARC\n",
      "217\n",
      "INCORRECT:  Russias\n",
      "218\n",
      "INCORRECT:  Ewing\n",
      "219\n",
      "INCORRECT:  Jørgensen\n",
      "220\n",
      "INCORRECT:  speaker\n",
      "221\n",
      "CORRECT:  damages\n",
      "222\n",
      "CORRECT:  decree\n",
      "223\n",
      "INCORRECT:  hell\n",
      "224\n",
      "INCORRECT:  ascribed\n",
      "225\n",
      "CORRECT:  procedural\n",
      "226\n",
      "CORRECT:  activists\n",
      "227\n",
      "INCORRECT:  anxiety\n",
      "228\n",
      "INCORRECT:  Ecuador\n",
      "229\n",
      "INCORRECT:  Antunes\n",
      "230\n",
      "INCORRECT:  dragged\n",
      "231\n",
      "CORRECT:  twofold\n",
      "232\n",
      "INCORRECT:  stockpile\n",
      "233\n",
      "INCORRECT:  Come\n",
      "234\n",
      "CORRECT:  defended\n",
      "235\n",
      "CORRECT:  corrupt\n",
      "236\n",
      "INCORRECT:  preschool\n",
      "237\n",
      "CORRECT:  temptations\n",
      "238\n",
      "INCORRECT:  famous\n",
      "239\n",
      "INCORRECT:  Nicaragua\n",
      "240\n",
      "INCORRECT:  background\n",
      "241\n",
      "INCORRECT:  reinforcing\n",
      "242\n",
      "INCORRECT:  inspiring\n",
      "243\n",
      "INCORRECT:  omen\n",
      "244\n",
      "INCORRECT:  conforms\n",
      "245\n",
      "INCORRECT:  stress\n",
      "246\n",
      "CORRECT:  Ribeiro\n",
      "247\n",
      "INCORRECT:  orientation\n",
      "248\n",
      "INCORRECT:  inconvenient\n",
      "249\n",
      "INCORRECT:  counterfeiters\n",
      "250\n",
      "INCORRECT:  Participation\n",
      "251\n",
      "INCORRECT:  offering\n",
      "252\n",
      "INCORRECT:  Chiquita\n",
      "253\n",
      "INCORRECT:  stemming\n",
      "254\n",
      "INCORRECT:  bowed\n",
      "255\n",
      "CORRECT:  Production\n",
      "256\n",
      "INCORRECT:  thoughtful\n",
      "257\n",
      "INCORRECT:  payer\n",
      "258\n",
      "INCORRECT:  idealism\n",
      "259\n",
      "INCORRECT:  hire\n",
      "260\n",
      "CORRECT:  translations\n",
      "261\n",
      "CORRECT:  paradoxical\n",
      "262\n",
      "INCORRECT:  appeals\n",
      "263\n",
      "CORRECT:  antidiscrimination\n",
      "264\n",
      "INCORRECT:  overhauled\n",
      "265\n",
      "INCORRECT:  moderate\n",
      "266\n",
      "INCORRECT:  extra\n",
      "267\n",
      "INCORRECT:  hook\n",
      "268\n",
      "INCORRECT:  transplants\n",
      "269\n",
      "INCORRECT:  sanitary\n",
      "270\n",
      "CORRECT:  Bratislava\n",
      "271\n",
      "INCORRECT:  Mostar\n",
      "272\n",
      "INCORRECT:  Developing\n",
      "273\n",
      "CORRECT:  tensions\n",
      "274\n",
      "INCORRECT:  originating\n",
      "275\n",
      "CORRECT:  impetus\n",
      "276\n",
      "CORRECT:  exemptions\n",
      "277\n",
      "CORRECT:  disintegration\n",
      "278\n",
      "INCORRECT:  implicated\n",
      "279\n",
      "INCORRECT:  Lehtomäki\n",
      "280\n",
      "INCORRECT:  disposing\n",
      "281\n",
      "INCORRECT:  ruminants\n",
      "282\n",
      "CORRECT:  Johannesburg\n",
      "283\n",
      "INCORRECT:  Philip\n",
      "284\n",
      "INCORRECT:  motorcycle\n",
      "285\n",
      "INCORRECT:  untold\n",
      "286\n",
      "CORRECT:  demonstrated\n",
      "287\n",
      "INCORRECT:  superfluous\n",
      "288\n",
      "CORRECT:  recourse\n",
      "289\n",
      "CORRECT:  injustices\n",
      "290\n",
      "INCORRECT:  phytosanitary\n",
      "291\n",
      "INCORRECT:  makers\n",
      "292\n",
      "INCORRECT:  EEC\n",
      "293\n",
      "CORRECT:  Five\n",
      "294\n",
      "CORRECT:  father\n",
      "295\n",
      "INCORRECT:  plates\n",
      "296\n",
      "INCORRECT:  EIA\n",
      "297\n",
      "CORRECT:  opposition\n",
      "298\n",
      "CORRECT:  gelatine\n",
      "299\n",
      "INCORRECT:  Criminal\n",
      "300\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "test_sample = np.random.choice(list(train_vocab),size=3000,replace=False)\n",
    "\n",
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "\n",
    "# test_tuple = pickle.load(open(\"test_tuple.pkl\", \"rb\"))\n",
    "\n",
    "for i, tup in enumerate(test_italian):\n",
    "    print(i)\n",
    "    if i == 300:\n",
    "        break\n",
    "    \n",
    "    word = tup[0]\n",
    "    french_word = tup[1]\n",
    "    \n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word,src=\"en\",dest=\"fr\").text\n",
    "#     if french_word not in french_vocab or word == french_word or word[0].isupper():\n",
    "#         continue\n",
    "    output_list = predict_cosineSim(word,20)\n",
    "    output_set = set(output_list)\n",
    "    \n",
    "#     test_tuple.add((word,french_word))\n",
    "#     print(i)\n",
    "    \n",
    "    if french_word in output_set:\n",
    "        num_correct += 1\n",
    "        print('CORRECT:  ' + word)\n",
    "    else:\n",
    "#         flag = False\n",
    "#         for word_fr in output_list:\n",
    "#             if translator.translate(word_fr,src=\"fr\",dest=\"en\").text == word:\n",
    "#                 num_correct += 1\n",
    "#                 print('CORRECT:  ' + word)\n",
    "#                 flag = True\n",
    "#                 break\n",
    "#         if not flag:\n",
    "        num_incorrect += 1\n",
    "        print('INCORRECT:  ' + word)\n",
    "\n",
    "# with open('test_tuple.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_tuple, f)\n",
    "\n",
    "acc = num_correct / (num_correct + num_incorrect)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 46.33% -- Accuracy achieved with part 1's transformation matrix\n",
    "# 47% -- baseline, with normalization\n",
    "\n",
    "# 43% -- 500\n",
    "# 44% -- 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
