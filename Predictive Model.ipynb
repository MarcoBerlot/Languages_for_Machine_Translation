{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "from googletrans import Translator  # Import Translator module from googletrans package\n",
    "import _dynet as dy\n",
    "\n",
    "train_data = pickle.load(open(\"train_data.pkl\", \"rb\"))\n",
    "test_data = pickle.load(open(\"test_data.pkl\", \"rb\"))\n",
    "val_data = pickle.load(open(\"val_data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createCorpus():\n",
    "    corpus_fr=[]\n",
    "    corpus_en=[]\n",
    "    puncList = [\".\",\";\",\":\",\"!\",\"?\",\"/\",\"\\\\\",\",\",\"#\",\"@\",\"$\",\"&\",\")\",\"(\",\"\\\"\",\"...\"]\n",
    "    i=0\n",
    "    with open (\"train_fr.fr\", \"r\",encoding=\"utf8\") as myfile:\n",
    "        for line in myfile:\n",
    "            sentence=[]\n",
    "            for word in line.split(\" \"):\n",
    "                word=word.replace(\"\\n\",\"\")\n",
    "                if(word not in puncList):\n",
    "                    if word.replace('.','',1).isdigit():\n",
    "                        word=\"DIG\"\n",
    "                    sentence.append(word) \n",
    "            corpus_fr.append(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    with open (\"train_en.en\", \"r\",encoding=\"utf8\") as myfile:\n",
    "        for line in myfile:\n",
    "            sentence=[]\n",
    "            for word in line.split(\" \"):\n",
    "                word=word.replace(\"\\n\",\"\")\n",
    "                if(word not in puncList):\n",
    "                    if word.replace('.','',1).isdigit():\n",
    "                        word=\"DIG\"\n",
    "                    sentence.append(word) \n",
    "            corpus_en.append(sentence)\n",
    "\n",
    "    with open('corpus_en.pkl', 'wb') as f:\n",
    "        pickle.dump(corpus_en, f)\n",
    "    with open('corpus_fr.pkl', 'wb') as f:\n",
    "        pickle.dump(corpus_fr, f)\n",
    "    \n",
    "    return corpus_en, corpus_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corpus_en, corpus_fr = createCorpus()\n",
    "corpus_en = pickle.load(open(\"corpus_en.pkl\", \"rb\"))\n",
    "corpus_fr = pickle.load(open(\"corpus_fr.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_en) == len(corpus_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dictionary for word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createW2V():\n",
    "    model_en=word2vec.Word2Vec(corpus_en,min_count=1)\n",
    "    model_fr=word2vec.Word2Vec(corpus_fr,min_count=1)\n",
    "\n",
    "    with open('model_en.pkl', 'wb') as f:\n",
    "        pickle.dump(model_en, f)\n",
    "    with open('model_fr.pkl', 'wb') as f:\n",
    "        pickle.dump(model_fr, f)\n",
    "    \n",
    "    return model_en, model_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_en, model_fr = createW2V()\n",
    "model_en = pickle.load(open(\"model_en.pkl\", \"rb\"))\n",
    "model_fr = pickle.load(open(\"model_fr.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_fr = model_fr[model_fr.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_en = model_en[model_en.wv.vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "result_fr_pca = pca.fit_transform(X_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "result_en_pca = pca.fit_transform(X_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un\n",
      "deux\n",
      "trois\n",
      "quatre\n",
      "cinq\n",
      "six\n",
      "sept\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nphAQEQmYQkBEJGAKARGRgP1/gxVP6dw+YAIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ad99b7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#FRENCH\n",
    "# create a scatter plot of the projection\n",
    "index_fr=[list(model_fr.wv.vocab).index(\"un\"),list(model_fr.wv.vocab).index(\"deux\"),list(model_fr.wv.vocab).index(\"trois\"),list(model_fr.wv.vocab).index(\"quatre\"),list(model_fr.wv.vocab).index(\"cinq\"),list(model_fr.wv.vocab).index(\"six\"),list(model_fr.wv.vocab).index(\"sept\")]\n",
    "result_fr=np.array([result_fr_pca[i] for i in index_fr])\n",
    "plt.scatter(-result_fr[:, 0],-result_fr[:, 1])\n",
    "fr_words = [ list(model_fr.wv.vocab)[i] for i in index_fr]\n",
    "for i, word in enumerate(fr_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(-result_fr[i, 0], -result_fr[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npHAXEQkghbuISAAp3EVEAuj/A1J+12VuizvaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bdc64710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ENGLISH\n",
    "# create a scatter plot of the projection\n",
    "index_en=[list(model_en.wv.vocab).index(\"one\"),list(model_en.wv.vocab).index(\"two\"),list(model_en.wv.vocab).index(\"three\"),list(model_en.wv.vocab).index(\"four\"),list(model_en.wv.vocab).index(\"five\"),list(model_en.wv.vocab).index(\"six\"),list(model_en.wv.vocab).index(\"seven\")]\n",
    "result_en=np.array([result_en_pca[i] for i in index_en])\n",
    "plt.scatter(result_en[:, 0], result_en[:, 1])\n",
    "en_words = [ list(model_en.wv.vocab)[i] for i in index_en]\n",
    "for i, word in enumerate(en_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(result_en[i, 0], result_en[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_word = []\n",
    "english_vocab = set()\n",
    "for sentence in corpus_en:\n",
    "    for word in sentence:\n",
    "        all_word.append(word)\n",
    "        english_vocab.add(word)\n",
    "        \n",
    "french_vocab = set()\n",
    "for sentence in corpus_fr:\n",
    "    for word in sentence:\n",
    "        french_vocab.add(word)\n",
    "        \n",
    "counts = Counter(all_word)\n",
    "common_vocab = set()\n",
    "train_vocab = set()\n",
    "for word in counts.most_common(70000):\n",
    "    common_vocab.add(word[0])\n",
    "for word in counts.most_common(10000):\n",
    "    train_vocab.add(word[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pairs of English-French Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateWordPairs():\n",
    "    word_pairs = []\n",
    "    word_pairs_smaller = []\n",
    "\n",
    "    count = 0\n",
    "    for word in english_vocab:\n",
    "        print(count)\n",
    "        count += 1\n",
    "        translator = Translator()\n",
    "        french_word = translator.translate(word,src=\"en\",dest=\"fr\").text\n",
    "        if french_word in french_vocab:\n",
    "            word_pairs.append((word, french_word))\n",
    "            if french_word != word:\n",
    "                word_pairs_smaller.append((word, french_word))\n",
    "\n",
    "    with open('word_pairs.pkl', 'wb') as f:\n",
    "        pickle.dump(word_pairs, f)\n",
    "    with open('word_pairs_smaller.pkl', 'wb') as f:\n",
    "        pickle.dump(word_pairs_smaller, f)\n",
    "    \n",
    "    return word_pairs, word_pairs_smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_pairs, word_pairs_smaller = generateWordPairs()\n",
    "word_pairs = pickle.load(open(\"word_pairs.pkl\", \"rb\"))\n",
    "# word_pairs_smaller = pickle.load(open(\"word_pairs_smaller.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square Method of Solving Transormation Matrix on 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateMat(size, dimm):\n",
    "    en_list = list(model_en.wv.vocab)\n",
    "    fr_list = list(model_fr.wv.vocab)\n",
    "\n",
    "    A = np.zeros((dimm*size, dimm*dimm))\n",
    "    b = np.zeros((dimm*size, 1))\n",
    "\n",
    "    count = 0\n",
    "    inds = np.random.choice(len(word_pairs),size=size,replace=False)\n",
    "    for i in range(len(inds)):\n",
    "        word_pair = word_pairs[inds[i]]\n",
    "        word_en = word_pair[0]\n",
    "        word_fr = word_pair[1]\n",
    "#         en_emb = X_en[en_list.index(word_en)]\n",
    "#         fr_emb = X_fr[fr_list.index(word_fr)]\n",
    "        en_emb = result_en_pca[en_list.index(word_en)]\n",
    "        fr_emb = result_fr_pca[fr_list.index(word_fr)]\n",
    "        \n",
    "        for j in range(dimm):\n",
    "            A[i*dimm+j,j*dimm:(j+1)*dimm] = en_emb\n",
    "            b[i*dimm+j] = fr_emb[j]\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "\n",
    "    A_trans = np.transpose(A)\n",
    "    coef = np.dot(np.dot(np.linalg.inv(np.dot(A_trans, A)), A_trans), b)\n",
    "\n",
    "    transform_mat = coef.reshape((dimm,dimm))\n",
    "    \n",
    "\n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = generateMat(1000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(emb):\n",
    "    out_emb = np.dot(mat, emb.reshape((len(emb),1)))\n",
    "    return out_emb.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENGLISH\n",
    "# create a scatter plot of the projection\n",
    "index_en=[list(model_en.wv.vocab).index(\"one\"),list(model_en.wv.vocab).index(\"two\"),list(model_en.wv.vocab).index(\"three\"),list(model_en.wv.vocab).index(\"four\"),list(model_en.wv.vocab).index(\"five\"),list(model_en.wv.vocab).index(\"six\"),list(model_en.wv.vocab).index(\"seven\")]\n",
    "result_en=np.array([transform(result_en_pca[i]) for i in index_en])\n",
    "plt.scatter(result_en[:, 0], result_en[:, 1])\n",
    "en_words = [ list(model_en.wv.vocab)[i] for i in index_en]\n",
    "for i, word in enumerate(en_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(result_en[i, 0], result_en[i, 1]))\n",
    "# plt.show()\n",
    "\n",
    "index_fr=[list(model_fr.wv.vocab).index(\"un\"),list(model_fr.wv.vocab).index(\"deux\"),list(model_fr.wv.vocab).index(\"trois\"),list(model_fr.wv.vocab).index(\"quatre\"),list(model_fr.wv.vocab).index(\"cinq\"),list(model_fr.wv.vocab).index(\"six\"),list(model_fr.wv.vocab).index(\"sept\")]\n",
    "result_fr=np.array([result_fr_pca[i] for i in index_fr])\n",
    "plt.scatter(result_fr[:, 0],result_fr[:, 1])\n",
    "fr_words = [ list(model_fr.wv.vocab)[i] for i in index_fr]\n",
    "for i, word in enumerate(fr_words):\n",
    "    print(word)\n",
    "    plt.annotate(word, xy=(result_fr[i, 0], result_fr[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_arr = np.array(list(model_fr.wv.vocab))\n",
    "en_list = list(model_en.wv.vocab)\n",
    "def predict_2d(word_en,topWords):\n",
    "    en_emb = result_en_pca[en_list.index(word_en)]\n",
    "    translator = Translator()\n",
    "    french_word = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "    return list(word_arr[np.argsort(np.sum((result_fr_pca - transform(en_emb)) ** 2,axis=1))[:topWords]]), french_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_2d('porch',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dynet Method of solving N-DIMM transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_list = list(model_en.wv.vocab)\n",
    "fr_list = list(model_fr.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTransormMatOriginal():\n",
    "    \n",
    "    DIMM = X_en.shape[1]\n",
    "\n",
    "    dyparams = dy.DynetParams()\n",
    "    dyparams.set_mem(2048)\n",
    "    dyparams.set_autobatch(True)\n",
    "    dyparams.init()\n",
    "\n",
    "    # create a parameter collection and add the parameters.\n",
    "    m = dy.ParameterCollection()\n",
    "    pW = m.add_parameters((DIMM,DIMM))\n",
    "    pb = m.add_parameters((DIMM))\n",
    "\n",
    "    dy.renew_cg() # new computation graph. not strictly needed here, but good practice.\n",
    "\n",
    "    # associate the parameters with cg Expressions\n",
    "    W = dy.parameter(pW)\n",
    "    b = dy.parameter(pb)\n",
    "\n",
    "    x = dy.vecInput(DIMM) # an input vector of size 2. Also an expression.\n",
    "    y = dy.vecInput(DIMM)\n",
    "    output = W*x\n",
    "\n",
    "    SIZE = len(word_pairs)\n",
    "\n",
    "    trainer = dy.SimpleSGDTrainer(m)\n",
    "\n",
    "    EPOCHS = 5\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        inds = np.random.choice(len(word_pairs),size=SIZE,replace=False)\n",
    "        total_loss = 0\n",
    "        seen_instances = 0\n",
    "        for i in range(len(inds)):\n",
    "            word_pair = word_pairs[inds[i]]\n",
    "            word_en = word_pair[0]\n",
    "            word_fr = word_pair[1]\n",
    "            en_emb = X_en[en_list.index(word_en)]\n",
    "            fr_emb = X_fr[fr_list.index(word_fr)]\n",
    "\n",
    "            x.set(en_emb)\n",
    "            y.set(fr_emb)\n",
    "\n",
    "            loss = dy.squared_distance(output,y)\n",
    "            seen_instances += 1\n",
    "            total_loss += loss.value()\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            if (seen_instances > 1 and seen_instances % 1000 == 0):\n",
    "                print (\"average loss is:\",total_loss / seen_instances)\n",
    "                seen_instances = 0\n",
    "                total_loss = 0\n",
    "\n",
    "    mat = W.value()\n",
    "\n",
    "    with open('mat.pkl', 'wb') as f:\n",
    "        pickle.dump(mat, f)\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mat = generateTransormMatOriginal()\n",
    "mat = pickle.load(open(\"mat.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Method  -----This is the method for generating transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIMM = X_en.shape[1]\n",
    "HIDDEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTransormMatImproved():\n",
    "    \n",
    "#     training_tuples = pickle.load(open(\"training_tuples.pkl\", \"rb\"))\n",
    "\n",
    "    dyparams = dy.DynetParams()\n",
    "    dyparams.set_mem(2048)\n",
    "    dyparams.set_autobatch(True)\n",
    "    dyparams.init()\n",
    "\n",
    "    # create a parameter collection and add the parameters.\n",
    "    m = dy.ParameterCollection()\n",
    "    pW = m.add_parameters((DIMM,DIMM))\n",
    "    pb = m.add_parameters((HIDDEN))\n",
    "    pC = m.add_parameters((DIMM,HIDDEN))\n",
    "\n",
    "    dy.renew_cg() # new computation graph. not strictly needed here, but good practice.\n",
    "\n",
    "    # associate the parameters with cg Expressions\n",
    "    W = dy.parameter(pW)\n",
    "    b = dy.parameter(pb)\n",
    "    C = dy.parameter(pC)\n",
    "\n",
    "    x = dy.vecInput(DIMM) # an input vector of size 2. Also an expression.\n",
    "    y = dy.vecInput(DIMM)\n",
    "#     output = C*(W*x + b)\n",
    "    output = W*x\n",
    "    \n",
    "    SIZE = 10000\n",
    "\n",
    "    trainer = dy.SimpleSGDTrainer(m)\n",
    "\n",
    "    en_list = list(model_en.wv.vocab)\n",
    "    fr_list = list(model_fr.wv.vocab)\n",
    "\n",
    "\n",
    "    EPOCHS = 1\n",
    "\n",
    "#     words = np.random.choice(list(common_vocab),size=SIZE,replace=False)\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        seen_instances = 0\n",
    "        for i,tup in enumerate(train_data):\n",
    "            word_en = tup[0]\n",
    "            word_fr = tup[1]\n",
    "#             translator = Translator()\n",
    "#             word_fr = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "#             if word_fr not in french_vocab:\n",
    "#                 continue\n",
    "                \n",
    "#             training_tuples.add((word_en,word_fr))\n",
    "            \n",
    "            en_emb = X_en[en_list.index(word_en)]\n",
    "            fr_emb = X_fr[fr_list.index(word_fr)]\n",
    "\n",
    "            en_emb /= np.linalg.norm(en_emb)\n",
    "            fr_emb /= np.linalg.norm(fr_emb)\n",
    "\n",
    "            x.set(en_emb)\n",
    "            y.set(fr_emb)\n",
    "        \n",
    "#             loss = 1 - dy.dot_product(output,y) / (dy.l2_norm(output) * dy.l2_norm(y)).value()\n",
    "            \n",
    "            loss = dy.squared_distance(output,y)\n",
    "        \n",
    "            seen_instances += 1\n",
    "            total_loss += loss.value()\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            \n",
    "#             tmp = W.value()\n",
    "#             u, s, vh = np.linalg.svd(tmp, full_matrices=True)\n",
    "#             newW = np.dot(u,vh)\n",
    "            \n",
    "#             pW = m.add_parameters((DIMM,DIMM),init=dy.NumpyInitializer(newW))\n",
    "#             W = dy.parameter(pW)\n",
    "\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(total_loss / seen_instances)\n",
    "                print(i)\n",
    "\n",
    "    mat = W.value()\n",
    "    matC = C.value()\n",
    "    matB = b.value()\n",
    "    \n",
    "#     with open('training_tuples.pkl', 'wb') as f:\n",
    "#         pickle.dump(training_tuples, f)\n",
    "    \n",
    "    return mat, matC, matB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8117375373840332\n",
      "0\n",
      "1.2877212851354392\n",
      "100\n",
      "1.162362343488048\n",
      "200\n",
      "1.111530193557771\n",
      "300\n",
      "1.0413392929364915\n",
      "400\n",
      "0.9966268046887335\n",
      "500\n",
      "0.9671682212098862\n",
      "600\n",
      "0.9419510087341113\n",
      "700\n",
      "0.9199089260025417\n",
      "800\n",
      "0.9012849886429296\n",
      "900\n",
      "0.8907075647737358\n",
      "1000\n",
      "0.8769615410432071\n",
      "1100\n",
      "0.8668877320250901\n",
      "1200\n",
      "0.8530014375944855\n",
      "1300\n",
      "0.8469731006066685\n",
      "1400\n",
      "0.838802314604782\n",
      "1500\n",
      "0.8305554540082114\n",
      "1600\n",
      "0.8238396509509448\n",
      "1700\n",
      "0.8182656447931106\n",
      "1800\n",
      "0.8154986946285555\n",
      "1900\n",
      "0.8128306388199658\n",
      "2000\n",
      "0.8063207268431208\n",
      "2100\n",
      "0.8009383315283946\n",
      "2200\n",
      "0.7980274280378581\n",
      "2300\n",
      "0.7930324847054749\n",
      "2400\n",
      "0.7888070308580631\n",
      "2500\n",
      "0.7852260759361704\n",
      "2600\n",
      "0.7812668652898159\n",
      "2700\n",
      "0.7770073503383522\n",
      "2800\n",
      "0.7736934510254523\n",
      "2900\n",
      "0.7712253461834273\n",
      "3000\n",
      "0.7682628065097797\n",
      "3100\n",
      "0.7640565080322053\n",
      "3200\n",
      "0.7617445690357046\n",
      "3300\n",
      "0.7599647255924932\n",
      "3400\n",
      "0.7578497931544218\n",
      "3500\n",
      "0.7559446340690087\n",
      "3600\n",
      "0.7546360856075603\n",
      "3700\n",
      "0.7516831772848356\n",
      "3800\n",
      "0.7502658167876393\n",
      "3900\n",
      "0.7473742898197002\n",
      "4000\n",
      "0.7476726502463515\n",
      "4100\n",
      "0.7466775221651266\n",
      "4200\n",
      "0.7450762053882762\n",
      "4300\n",
      "0.744724107012779\n",
      "4400\n",
      "0.7437968301994221\n",
      "4500\n",
      "0.742374469701608\n",
      "4600\n",
      "0.7414203156812017\n",
      "4700\n",
      "0.7409713123179158\n",
      "4800\n",
      "0.738895109309831\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "mat, C, b = generateTransormMatImproved()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Prediction Method -- this is the prediction method using transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_arr = np.array(list(model_fr.wv.vocab))\n",
    "X_fr_mag = np.sum(X_fr**2,axis=1)**0.5\n",
    "def predict_cosineSim(word_en,topWords):\n",
    "    en_emb = X_en[en_list.index(word_en)]\n",
    "#     out = (np.dot(C,(np.dot(mat,en_emb.reshape((DIMM,1))) + np.array(b).reshape((HIDDEN,1))))).flatten()\n",
    "    out = np.dot(mat,en_emb.reshape((DIMM,1))).flatten()\n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "    \n",
    "    out_mag = np.sum(out**2)**0.5\n",
    "    cos_sim = np.sum((X_fr * out),axis=1)/(X_fr_mag*out_mag)\n",
    "    return list(word_arr[np.argsort(cos_sim)[::-1][:topWords]])#, french_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agrumes', 'biscuits', 'gâteaux', 'sauces', 'saucisses']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cosineSim('chocolate',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05856398, -0.01891301,  0.14371952, ...,  0.02430679,\n",
       "         0.06067046,  0.02653935],\n",
       "       [ 0.03369197,  0.06212052,  0.04053268, ...,  0.09182187,\n",
       "         0.03907124, -0.03148458],\n",
       "       [-0.13856173,  0.06481858,  0.0767872 , ..., -0.08383739,\n",
       "        -0.01502783, -0.07328853],\n",
       "       ...,\n",
       "       [ 0.02980525, -0.01074789, -0.03619723, ..., -0.04663319,\n",
       "         0.05263432, -0.00372449],\n",
       "       [-0.01757441, -0.06776521,  0.06201397, ..., -0.04451933,\n",
       "         0.10012314, -0.01414686],\n",
       "       [-0.00498244,  0.0764556 ,  0.09849447, ...,  0.03067609,\n",
       "         0.01351042,  0.03287015]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worse Prediction Method -- ignore this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_arr = np.array(list(model_fr.wv.vocab))\n",
    "def predict_closest(word_en,topWords):\n",
    "    en_emb = X_en[en_list.index(word_en)]\n",
    "    out = np.dot(mat,en_emb.reshape((DIMM,1))).flatten()\n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word_en,src=\"en\",dest=\"fr\").text\n",
    "    \n",
    "    return list(word_arr[np.argsort(np.sum((X_fr - out) ** 2,axis=1))[:topWords]])#, french_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_closest('chocolate',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of Model -- running this gets the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "INCORRECT:  pretext\n",
      "1\n",
      "INCORRECT:  junction\n",
      "2\n",
      "INCORRECT:  salad\n",
      "3\n",
      "INCORRECT:  enable\n",
      "4\n",
      "INCORRECT:  basically\n",
      "5\n",
      "CORRECT:  and\n",
      "6\n",
      "INCORRECT:  collateral\n",
      "7\n",
      "CORRECT:  sexuality\n",
      "8\n",
      "INCORRECT:  reservations\n",
      "9\n",
      "INCORRECT:  region\n",
      "10\n",
      "CORRECT:  cancelled\n",
      "11\n",
      "CORRECT:  frequently\n",
      "12\n",
      "CORRECT:  minority\n",
      "13\n",
      "INCORRECT:  requests\n",
      "14\n",
      "INCORRECT:  topic\n",
      "15\n",
      "INCORRECT:  motion\n",
      "16\n",
      "CORRECT:  width\n",
      "17\n",
      "CORRECT:  delivery\n",
      "18\n",
      "CORRECT:  sensitive\n",
      "19\n",
      "CORRECT:  teaching\n",
      "20\n",
      "CORRECT:  beautifully\n",
      "21\n",
      "INCORRECT:  juvenile\n",
      "22\n",
      "INCORRECT:  investigate\n",
      "23\n",
      "CORRECT:  button\n",
      "24\n",
      "INCORRECT:  working\n",
      "25\n",
      "INCORRECT:  voter\n",
      "26\n",
      "INCORRECT:  specific\n",
      "27\n",
      "INCORRECT:  little\n",
      "28\n",
      "CORRECT:  painful\n",
      "29\n",
      "INCORRECT:  corridor\n",
      "30\n",
      "CORRECT:  dry\n",
      "31\n",
      "INCORRECT:  associates\n",
      "32\n",
      "INCORRECT:  mighty\n",
      "33\n",
      "INCORRECT:  emerging\n",
      "34\n",
      "INCORRECT:  return\n",
      "35\n",
      "INCORRECT:  evidence\n",
      "36\n",
      "CORRECT:  elder\n",
      "37\n",
      "INCORRECT:  showing\n",
      "38\n",
      "CORRECT:  liberation\n",
      "39\n",
      "INCORRECT:  bowl\n",
      "40\n",
      "INCORRECT:  sharp\n",
      "41\n",
      "CORRECT:  transportation\n",
      "42\n",
      "INCORRECT:  trips\n",
      "43\n",
      "CORRECT:  age\n",
      "44\n",
      "CORRECT:  neutral\n",
      "45\n",
      "INCORRECT:  bother\n",
      "46\n",
      "INCORRECT:  fairly\n",
      "47\n",
      "CORRECT:  contacted\n",
      "48\n",
      "CORRECT:  street\n",
      "49\n",
      "INCORRECT:  speculative\n",
      "50\n",
      "CORRECT:  mothers\n",
      "51\n",
      "INCORRECT:  trigger\n",
      "52\n",
      "CORRECT:  shares\n",
      "53\n",
      "INCORRECT:  ordered\n",
      "54\n",
      "INCORRECT:  runway\n",
      "55\n",
      "INCORRECT:  president\n",
      "56\n",
      "INCORRECT:  meantime\n",
      "57\n",
      "INCORRECT:  spoken\n",
      "58\n",
      "CORRECT:  unconstitutional\n",
      "59\n",
      "INCORRECT:  challenges\n",
      "60\n",
      "CORRECT:  equitable\n",
      "61\n",
      "INCORRECT:  lesser\n",
      "62\n",
      "INCORRECT:  advocates\n",
      "63\n",
      "CORRECT:  passengers\n",
      "64\n",
      "INCORRECT:  favoured\n",
      "65\n",
      "INCORRECT:  bottom\n",
      "66\n",
      "CORRECT:  eight\n",
      "67\n",
      "CORRECT:  layer\n",
      "68\n",
      "CORRECT:  peoples\n",
      "69\n",
      "CORRECT:  terrorist\n",
      "70\n",
      "INCORRECT:  handy\n",
      "71\n",
      "INCORRECT:  puts\n",
      "72\n",
      "INCORRECT:  exposing\n",
      "73\n",
      "INCORRECT:  feel\n",
      "74\n",
      "CORRECT:  gene\n",
      "75\n",
      "CORRECT:  complaints\n",
      "76\n",
      "CORRECT:  diseases\n",
      "77\n",
      "INCORRECT:  attempt\n",
      "78\n",
      "INCORRECT:  because\n",
      "79\n",
      "INCORRECT:  think\n",
      "80\n",
      "INCORRECT:  drawn\n",
      "81\n",
      "INCORRECT:  awareness\n",
      "82\n",
      "INCORRECT:  shapes\n",
      "83\n",
      "CORRECT:  biometric\n",
      "84\n",
      "CORRECT:  write\n",
      "85\n",
      "CORRECT:  flights\n",
      "86\n",
      "INCORRECT:  pitch\n",
      "87\n",
      "INCORRECT:  draws\n",
      "88\n",
      "CORRECT:  strings\n",
      "89\n",
      "CORRECT:  sisters\n",
      "90\n",
      "CORRECT:  friends\n",
      "91\n",
      "CORRECT:  cemetery\n",
      "92\n",
      "INCORRECT:  imposing\n",
      "93\n",
      "INCORRECT:  triple\n",
      "94\n",
      "INCORRECT:  branch\n",
      "95\n",
      "CORRECT:  end\n",
      "96\n",
      "INCORRECT:  customary\n",
      "97\n",
      "INCORRECT:  due\n",
      "98\n",
      "INCORRECT:  intent\n",
      "99\n",
      "INCORRECT:  approaching\n",
      "100\n",
      "CORRECT:  organizing\n",
      "101\n",
      "INCORRECT:  expenditure\n",
      "102\n",
      "CORRECT:  mechanical\n",
      "103\n",
      "INCORRECT:  consider\n",
      "104\n",
      "INCORRECT:  cute\n",
      "105\n",
      "INCORRECT:  accommodate\n",
      "106\n",
      "INCORRECT:  fighter\n",
      "107\n",
      "CORRECT:  materials\n",
      "108\n",
      "CORRECT:  heroin\n",
      "109\n",
      "INCORRECT:  planes\n",
      "110\n",
      "CORRECT:  decrease\n",
      "111\n",
      "INCORRECT:  correspondent\n",
      "112\n",
      "CORRECT:  announce\n",
      "113\n",
      "INCORRECT:  revenue\n",
      "114\n",
      "INCORRECT:  agreement\n",
      "115\n",
      "INCORRECT:  towards\n",
      "116\n",
      "INCORRECT:  exploring\n",
      "117\n",
      "INCORRECT:  ability\n",
      "118\n",
      "INCORRECT:  continuously\n",
      "119\n",
      "CORRECT:  legacy\n",
      "120\n",
      "CORRECT:  tolerate\n",
      "121\n",
      "CORRECT:  exclusive\n",
      "122\n",
      "CORRECT:  policemen\n",
      "123\n",
      "INCORRECT:  stand\n",
      "124\n",
      "INCORRECT:  18th\n",
      "125\n",
      "INCORRECT:  west\n",
      "126\n",
      "INCORRECT:  economy\n",
      "127\n",
      "CORRECT:  himself\n",
      "128\n",
      "CORRECT:  restructuring\n",
      "129\n",
      "CORRECT:  heritage\n",
      "130\n",
      "CORRECT:  belief\n",
      "131\n",
      "INCORRECT:  rock\n",
      "132\n",
      "INCORRECT:  dioxide\n",
      "133\n",
      "INCORRECT:  academic\n",
      "134\n",
      "INCORRECT:  lowered\n",
      "135\n",
      "CORRECT:  rebuild\n",
      "136\n",
      "INCORRECT:  rather\n",
      "137\n",
      "CORRECT:  form\n",
      "138\n",
      "CORRECT:  manufactures\n",
      "139\n",
      "INCORRECT:  smoothly\n",
      "140\n",
      "CORRECT:  prayers\n",
      "141\n",
      "INCORRECT:  yard\n",
      "142\n",
      "INCORRECT:  comprised\n",
      "143\n",
      "INCORRECT:  closing\n",
      "144\n",
      "INCORRECT:  assure\n",
      "145\n",
      "CORRECT:  army\n",
      "146\n",
      "INCORRECT:  covers\n",
      "147\n",
      "CORRECT:  greeted\n",
      "148\n",
      "CORRECT:  vehicle\n",
      "149\n",
      "INCORRECT:  killing\n",
      "150\n",
      "INCORRECT:  died\n",
      "151\n",
      "INCORRECT:  critic\n",
      "152\n",
      "CORRECT:  fully\n",
      "153\n",
      "INCORRECT:  climbed\n",
      "154\n",
      "CORRECT:  supposedly\n",
      "155\n",
      "CORRECT:  gardens\n",
      "156\n",
      "INCORRECT:  permitting\n",
      "157\n",
      "CORRECT:  demonstrates\n",
      "158\n",
      "INCORRECT:  taxi\n",
      "159\n",
      "CORRECT:  blocked\n",
      "160\n",
      "INCORRECT:  photograph\n",
      "161\n",
      "INCORRECT:  research\n",
      "162\n",
      "CORRECT:  window\n",
      "163\n",
      "CORRECT:  concern\n",
      "164\n",
      "INCORRECT:  displaced\n",
      "165\n",
      "CORRECT:  two\n",
      "166\n",
      "CORRECT:  voting\n",
      "167\n",
      "CORRECT:  principally\n",
      "168\n",
      "INCORRECT:  herself\n",
      "169\n",
      "INCORRECT:  desk\n",
      "170\n",
      "CORRECT:  personality\n",
      "171\n",
      "INCORRECT:  here\n",
      "172\n",
      "CORRECT:  amend\n",
      "173\n",
      "INCORRECT:  outlet\n",
      "174\n",
      "INCORRECT:  extract\n",
      "175\n",
      "INCORRECT:  fly\n",
      "176\n",
      "CORRECT:  proximity\n",
      "177\n",
      "CORRECT:  priests\n",
      "178\n",
      "CORRECT:  town\n",
      "179\n",
      "INCORRECT:  projected\n",
      "180\n",
      "INCORRECT:  dealing\n",
      "181\n",
      "INCORRECT:  tendency\n",
      "182\n",
      "INCORRECT:  delayed\n",
      "183\n",
      "INCORRECT:  banned\n",
      "184\n",
      "CORRECT:  browser\n",
      "185\n",
      "CORRECT:  send\n",
      "186\n",
      "CORRECT:  nuclear\n",
      "187\n",
      "CORRECT:  coaches\n",
      "188\n",
      "CORRECT:  arrival\n",
      "189\n",
      "CORRECT:  minimize\n",
      "190\n",
      "CORRECT:  rigorous\n",
      "191\n",
      "INCORRECT:  cargo\n",
      "192\n",
      "INCORRECT:  failing\n",
      "193\n",
      "CORRECT:  gun\n",
      "194\n",
      "INCORRECT:  purpose\n",
      "195\n",
      "CORRECT:  authorised\n",
      "196\n",
      "INCORRECT:  grown\n",
      "197\n",
      "INCORRECT:  lower\n",
      "198\n",
      "CORRECT:  pianist\n",
      "199\n",
      "CORRECT:  organising\n",
      "200\n",
      "CORRECT:  define\n",
      "201\n",
      "INCORRECT:  inception\n",
      "202\n",
      "CORRECT:  monitored\n",
      "203\n",
      "CORRECT:  regimes\n",
      "204\n",
      "INCORRECT:  tied\n",
      "205\n",
      "CORRECT:  erected\n",
      "206\n",
      "CORRECT:  tortured\n",
      "207\n",
      "INCORRECT:  posting\n",
      "208\n",
      "CORRECT:  chosen\n",
      "209\n",
      "INCORRECT:  defect\n",
      "210\n",
      "INCORRECT:  returned\n",
      "211\n",
      "CORRECT:  aid\n",
      "212\n",
      "INCORRECT:  canals\n",
      "213\n",
      "INCORRECT:  exhibition\n",
      "214\n",
      "INCORRECT:  rushed\n",
      "215\n",
      "CORRECT:  surely\n",
      "216\n",
      "CORRECT:  tales\n",
      "217\n",
      "CORRECT:  wines\n",
      "218\n",
      "CORRECT:  possibilities\n",
      "219\n",
      "INCORRECT:  surroundings\n",
      "220\n",
      "INCORRECT:  according\n",
      "221\n",
      "CORRECT:  digital\n",
      "222\n",
      "CORRECT:  tank\n",
      "223\n",
      "CORRECT:  considerably\n",
      "224\n",
      "CORRECT:  test\n",
      "225\n",
      "CORRECT:  crowd\n",
      "226\n",
      "INCORRECT:  summoned\n",
      "227\n",
      "CORRECT:  fighting\n",
      "228\n",
      "INCORRECT:  referring\n",
      "229\n",
      "INCORRECT:  joining\n",
      "230\n",
      "CORRECT:  landings\n",
      "231\n",
      "CORRECT:  authorized\n",
      "232\n",
      "CORRECT:  declared\n",
      "233\n",
      "CORRECT:  cocaine\n",
      "234\n",
      "INCORRECT:  imported\n",
      "235\n",
      "INCORRECT:  organic\n",
      "236\n",
      "INCORRECT:  grew\n",
      "237\n",
      "INCORRECT:  denying\n",
      "238\n",
      "INCORRECT:  talk\n",
      "239\n",
      "CORRECT:  responsibility\n",
      "240\n",
      "CORRECT:  committee\n",
      "241\n",
      "INCORRECT:  raw\n",
      "242\n",
      "INCORRECT:  believe\n",
      "243\n",
      "CORRECT:  strictly\n",
      "244\n",
      "INCORRECT:  class\n",
      "245\n",
      "CORRECT:  apartment\n",
      "246\n",
      "INCORRECT:  decades\n",
      "247\n",
      "CORRECT:  determines\n",
      "248\n",
      "INCORRECT:  high\n",
      "249\n",
      "INCORRECT:  prevented\n",
      "250\n",
      "INCORRECT:  misconduct\n",
      "251\n",
      "INCORRECT:  assessing\n",
      "252\n",
      "CORRECT:  thought\n",
      "253\n",
      "INCORRECT:  see\n",
      "254\n",
      "INCORRECT:  belt\n",
      "255\n",
      "INCORRECT:  ranked\n",
      "256\n",
      "INCORRECT:  guided\n",
      "257\n",
      "INCORRECT:  perform\n",
      "258\n",
      "CORRECT:  day\n",
      "259\n",
      "INCORRECT:  preceding\n",
      "260\n",
      "CORRECT:  province\n",
      "261\n",
      "CORRECT:  risk\n",
      "262\n",
      "INCORRECT:  sweeping\n",
      "263\n",
      "CORRECT:  separately\n",
      "264\n",
      "CORRECT:  warehouses\n",
      "265\n",
      "CORRECT:  repayment\n",
      "266\n",
      "CORRECT:  city\n",
      "267\n",
      "CORRECT:  hiring\n",
      "268\n",
      "CORRECT:  territory\n",
      "269\n",
      "CORRECT:  produced\n",
      "270\n",
      "CORRECT:  purchased\n",
      "271\n",
      "INCORRECT:  silent\n",
      "272\n",
      "CORRECT:  neighborhood\n",
      "273\n",
      "CORRECT:  times\n",
      "274\n",
      "CORRECT:  participate\n",
      "275\n",
      "CORRECT:  room\n",
      "276\n",
      "INCORRECT:  selected\n",
      "277\n",
      "CORRECT:  universe\n",
      "278\n",
      "INCORRECT:  versus\n",
      "279\n",
      "CORRECT:  soccer\n",
      "280\n",
      "INCORRECT:  twist\n",
      "281\n",
      "CORRECT:  receive\n",
      "282\n",
      "INCORRECT:  delivered\n",
      "283\n",
      "INCORRECT:  thereafter\n",
      "284\n",
      "INCORRECT:  warm\n",
      "285\n",
      "CORRECT:  guy\n",
      "286\n",
      "INCORRECT:  recipients\n",
      "287\n",
      "CORRECT:  escape\n",
      "288\n",
      "INCORRECT:  desperate\n",
      "289\n",
      "INCORRECT:  forensic\n",
      "290\n",
      "INCORRECT:  ambient\n",
      "291\n",
      "CORRECT:  inevitable\n",
      "292\n",
      "INCORRECT:  electric\n",
      "293\n",
      "INCORRECT:  converted\n",
      "294\n",
      "CORRECT:  protesters\n",
      "295\n",
      "INCORRECT:  submits\n",
      "296\n",
      "CORRECT:  wins\n",
      "297\n",
      "CORRECT:  fridge\n",
      "298\n",
      "CORRECT:  liberty\n",
      "299\n",
      "INCORRECT:  prefer\n",
      "300\n",
      "0.4633333333333333\n"
     ]
    }
   ],
   "source": [
    "test_sample = np.random.choice(list(train_vocab),size=3000,replace=False)\n",
    "\n",
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "\n",
    "# test_tuple = pickle.load(open(\"test_tuple.pkl\", \"rb\"))\n",
    "\n",
    "for i, tup in enumerate(val_data):\n",
    "    print(i)\n",
    "    if i == 300:\n",
    "        break\n",
    "    \n",
    "    word = tup[0]\n",
    "    french_word = tup[1]\n",
    "    \n",
    "#     translator = Translator()\n",
    "#     french_word = translator.translate(word,src=\"en\",dest=\"fr\").text\n",
    "#     if french_word not in french_vocab or word == french_word or word[0].isupper():\n",
    "#         continue\n",
    "    output_list = predict_cosineSim(word,20)\n",
    "    output_set = set(output_list)\n",
    "    \n",
    "#     test_tuple.add((word,french_word))\n",
    "#     print(i)\n",
    "    \n",
    "    if french_word in output_set:\n",
    "        num_correct += 1\n",
    "        print('CORRECT:  ' + word)\n",
    "    else:\n",
    "#         flag = False\n",
    "#         for word_fr in output_list:\n",
    "#             if translator.translate(word_fr,src=\"fr\",dest=\"en\").text == word:\n",
    "#                 num_correct += 1\n",
    "#                 print('CORRECT:  ' + word)\n",
    "#                 flag = True\n",
    "#                 break\n",
    "#         if not flag:\n",
    "        num_incorrect += 1\n",
    "        print('INCORRECT:  ' + word)\n",
    "\n",
    "# with open('test_tuple.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_tuple, f)\n",
    "\n",
    "acc = num_correct / (num_correct + num_incorrect)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 46.33% -- Accuracy achieved with part 1's transformation matrix\n",
    "# 47% -- baseline, with normalization\n",
    "\n",
    "# 43% -- 500\n",
    "# 44% -- 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
